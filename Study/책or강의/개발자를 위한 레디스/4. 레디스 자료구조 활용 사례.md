레디스의 커맨드가 제공하는 여러 커맨드는 대부분 애플리케이션 레벨에서도 구현될 수 있겠지만, 레디스 자료 구조에 내장된 함수를 이용해 원하는 기능을 사용하면 데이터를 애플리케이션 메모리 영역으로 가져간 뒤 가공하는 데에 걸리는 시간을 줄일 수 있기 때문에 레디스가 제공하는 다양한 자료 구조를 적절히 활용한다면 애플리케이션에서는 매우 짧은 대기시간으로 엄청난 양의 작업을 처리할 수 있다.

# SortedSet
## 리더보드
- 절대적 리더보드: 서비스의 모든 유저를 정렬시켜 상위권 목록만을 표기
- 상대적 리더보드: 사용자의 스코어를 기반으로 그들을 다른 사용자와 비교해 순위를 결정하는 형태의 리더보드

> 사용자가 속한 그룹 내에서 또는 특정 경쟁자와의 스코어 대결에서 상대적인 순위를 제공하며, 절대적인 모든 사용자를 대상으로 한 리더보드와는 다르다.
> 주로 사용자 간 경쟁과 상대적인 성과를 강조하는 리더보드 유형으로 나뉜다.

-> 기중치를 줄 수도 있으며, 랭킹 합산을 할 수 있다.
## 최근 검색 기록
- 유저별로 다른 키워드 노출
- 검색 내역은 중복 제거
- 가장 최근 검색한 5개 키워드만 사용자에게 노출

만일 위 요구사항을 RDB로 구현하려고 했다면, 많은 어려움이 있었을 것이다.
순서또한, 가중치(검색 일시)로 조정이 가능하며, set으로 인해서 자연스럽게 중복이 제거된다.
또, 가장 오래된 6번째 인덱스 데이터를 삭제한다면, 자연스럽게 최근 5개 키워드만 사용자에게 노출 할 수 있다.

## 태그기능
중복 제거 + 교집합 연산도 쉽게 할 수 있다.


# 레디스의 다양한 카운팅 방법

애플리케이션에서 데이터 개수를 세는 카운팅 작업은 자주 발생한다. 이러한 작업은 요구사항에 따라 다양한 형태로 이뤄질 수 있는데, 단순히 아이템의 개수를 파악해야 하는 경우도 있고, 어떤 아이템이 저장됬는지 함께 파악해야 하는경우도 있다.
때로는 ==약간의 오차를 허용하면서 매우 큰 데이터 셋을 빠르게 처리하고자 할 때도 있다==

## 좋아요 처리하기
포털 사이트의 좋아요 기능을 추가한다고 가정하자.
RDB를 사용했다면, DB에 직접적인 영향을 끼칠 수 있다. 또, 하나의 유저는 같은 댓글에 한 번씩만 좋아요를 누를 수 있어야 하기 때문에, 단순히 좋아요의 개수를 파악하는 것이 아닌, 어떤 유저가 어떤 댓글에 좋아요를 눌렀는지 데이터 처리를 할 수 있어야 한다.

- set을 활용

```reids-cli
> SADD comment-like:12554 967
(integer) 1
```
각 댓글별로 좋아요를 누른 수는 SCARD 커맨드로 확인할 수 있다.
```redis-cli
> SCARD comment-like:12554
(integer)3
```


## 읽지 않은 수 카운팅하기
채팅 메시지가 도착할 때마다 바로 관계형 데이터베이스를 업데이트 하는 대신 데이터를 레디스와 같은 인메모리 데이터베이스에 일시적으로 저장한뒤 필요한 시점에 한꺼번에 업데이트하는 방식을 이용하면, RDB의 부하를 최소화하고 성능을 향상시킬 수 있다.

좋아요와 달리, 중복 데이터를 고려할 필요없이 메시지 개수만 추가하면된다.

`user:123`으로 해시 자료형을 형성한다.
```redis-cli
HINCRBY user:234 channel:4234 1
```
누군가 이미 전송한 메시지를 삭제했다면 `HINCRBY`를 통해 음수값을 입력할 수도 있다.
```redis-cli
HINCRBY user:123 channel:3135 -1
```

hash구조는 객체 구조에서 카운트를 효과적으로 관리할 수 있다. 이 구조를 활용하면 사용자를 식별하고, 해당 채널을 찾아가서 데이터를 업데이트 할 수 있다.

## DAU구하기
`DAU(Daily Active User)`하루에 방문한 사용자 수.
하루에 여러번 방문했다 하더라도, 한 번으로 카운팅 되는 값으로, 실제 서비스를 사용한 사용자의 유니크한 수를 파악할 수 있는 지표이다. 

사용자 접근 로그와 같은 접속 로그를 활용해 날마다 배치 처리를 수행하는 방식으로 DAU를 계산할 수 있지만, 이런 방식으로는 실시간 데이터는 확인할 수 없다.

userId를 SET으로 저장하는 방법도 하나의 키 안에 너무 많은 값이 저장될 수 있으며, 이는 곧 성능의 저하로 이어질 수 있다. 또, 저장되는 데이터가 많을수록 메모리를 많이 차지하게 된다.

> 보통 키 하나당 저장하는 아이템은 최대 200만~300만 개까지로 조정할 것을 권장한다.

레디스의 `비트맵`을 이용하면, 메모리를 효율적으로 줄이면서도 실시간으로 서비스의 DAU를 활용할 수 있다.

> [!question] 사용자가 1000만명이 넘는 게임 서비스에서 레디스의 bit를 사용해 DAU를 측정하는 방법을 알아보자
> - 이 때 사용자 id는 0이상 정수값이다.

2024년 11월 6일 방문한 유저 id를 구하기 위해 키가 `uv:20241106`인 데이터를 만들어 접속한 유저 id의 bit를 1로 설정하면 된다. id가 14인 유저가 접근했을 때에는 오프셋 14를 1로 설정해준다.

```redis
SETBIT uv:20241106 14 1
(integer) 1
```

해당 일자에 접근한 유저 수를 확인할때는 `BITCOUNT`를 커맨드로 사용할 수 있다.
```redis-cli
BITCOUNT uv:20241106
(integer) 3
```
비트맵에서 `BITTOP`커맨드를 사용하면 `AND`, `OR`, `XOR`, `NOT`연산을 할 수 있으며, 레디스 서버에서 바로 계산된 결과를 가져올 수 있어, 개별 비트를 가져와 서버에서 처리하는 번거로움을 줄여줄 수 있다.

> [!example] 출석 이벤트 진행을 위해서 어떻게 구현할것인가
> - BITTOP AND 연산
> - `BITTOP AND event:202211 uv:20221101 uv:20221102 uv:20221103`


## hyperloglog을 이용한 애플리케이션 미터링
서버와 클라이언트에서 발생하는 로그를 수집하고, 인덱싱해 사용자가 특정 로그를 검색하고 조회할 수 있는 서비스를 클라우드 환경에 제공한다고 가정
이 때 로그를 수집할 때 마다 서비스의 API를 호풀하고 하나의 API의 호출마다 건별로 과금을 매기는 정책이 있다면, 사용자별 API호출 횟수를 카운팅 해야한다.

1초에 100개씩 로그가 쌓이는 서버가 존재한다고 가정하면, 한시간이면 36만개의 로그, 한 달이면 2억 6천 개 정도의 로그가 쌓일 수 있다. 이런 서버가 한 대가 아니라 여러 대가 존재하면 총 몇개의 로그가 쌓였는지 측정하는것 자체가 큰 부하가 된다.

아래 조건이 부합하면 redis의 hyperloglog를 사용하는것을 고려해 볼 수 있다.
- 집합 내 유일한 데이터의 개수를 카운팅
- 1%미만의 오차는 허용 가능하다.
- 카운팅할 때 정확한 데이터를 다시 확인하지 않아도 된다.

일반적인 방법으로 중복을 피하기 위해 저장된 데이터를 모두 기억해야 하므로, 저장되는 데이터가 많아질수록 많은 메모리를 사용한다. 하지만 저장된 값을 다시 확인하지 안하도 되는경우라 hyperloglog을 이용할 수 있다면 최소한의 메모리(`12KB`)만을 사용해 중복되지 않는 데이터 개수를 계산할 수 있다.

PFMERGE커맨드를 이용하면 여러 개의 hyperloglog를 합칠 수 있으므로, 분기별 또는 연도별 합산 데이터를 간편하게 계산할 수 있다.