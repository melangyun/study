캐시란 데이터의 원본보다 더 빠르고, 효율적으로 액세스 할 수 있는 `임시 데이터 저장소`를 의미한다.
애플리케이션이 다음 조건을 만족시킨다면, 캐시를 도입했을 때 성능을 효과적으로 개선할 수 있다.

- 원본 데이터 저장소에서 원하는 데이터를 찾기 위해 검색하는 시간이 오래걸리거나, 매번 계산을 통해 데이터를 가져와야 한다.
- 캐시에서 데이터를 가져오는 것이 원본 데이터 저장소 데이터를 요청하는 것보다 빨라야 한다.
- <mark style="background: #D2B3FFA6;">캐시에 저장된 데이터는 잘 변하지 않는 데이터이다.</mark>
- <mark style="background: #D2B3FFA6;">캐시에 저장된 데이터는 자주 검색되는 데이터이다.</mark>

중요한 데이터를 캐시에 올려두고, 사용할 때 원본 데이터 저장소에 장애가 발생해 접근할 수 없는 상황이 발생하더라도 캐시에서 데이터를 가지고 올 수 있기 때문에 장애 시간을 줄일 수 있다.

# 캐시로서의 레디스
레디스는 모든 데이터를 메모리에 저장하는 임메모리 데이터 저장소이기 때문에 데이터를 검색하고 반환하는것이 상당히 빠르다는 특징이 있다.

**고가용성**
레디스는 자체적으로 고가용성 기능을 가지고 있는 솔루션이라는 점도 큰 장점이 있다.
> 일부 캐싱 전략에서는 캐시에 접근할 수 없게되면, 이는 곧바로 서비스 장애로 이어질 수 있다.
> 따라서 캐시 저장소도 일반적인 데이터 저장소와 같이 안정적으로 운영될 수 있는 조건을 갖추는 것이 좋다.

- [i] 레디의 `센티널` 또는 `클러스터` 기능을 사용하면 마스터 노드의 장애를 자동으로 감지해 페일오버를 발생시키기 때문에 운영자의 개입 없이 캐시는 정상적으로 유지될 수 있어 가용성이 높아진다.

## 캐싱 전략
캐싱 전략은 캐싱되는 데이터의 유형과 데이터에 대한 액세스 패턴에 따라 다르기 때문에, 서비스에 맞는 적절한 캐싱 전략을 선택하는것이 중요하다.

### 1. 읽기 전략 - look aside
`가장 일반적인 전략`
![Look Aside](https://velog.velcdn.com/images/wellsy1012/post/0f119b33-2090-4314-9be8-13ad4b0980a1/image.png)
1. **캐시 히트**
   찾고자 하는 데이터가 캐시에 있는지 확인.
   캐시에 데이터가 있으면 캐시에서 데이터를 읽어온다.
2. **캐시 미스**
	찾고자 하는 데이터가 없다면 
	- 데이터 베이스에 직접 접근해 데이터를 가져온다
	- 캐시에 저장한다.

> [!tip] look aside전략의 경우 레디스에 문제가 생겼을 때에도 서비스에 장애가 생기지 않는다.
> 하지만, *레디스를 통해 데이터를 가져오는 연결이 매우 많았다면,* DB 부하가 발생되고, 이로 인해 원본 DB의 응답이 느려지거나 리소스를 많이 차지하는 등 이슈가 발생해 애플리케이션 성능에 영향을 끼칠 수 있따.

> [!warning] 처음레디스를 도입할 경우
> 애플리케이션은 데이터를 찾기 위해 레디스에 매번 접근할 것이고, 그 때마다 캐시 미스가 일어나 데이터 베이스와 레디스에 재접근하는 과정을 통해 지연이 초래돼 성능에 영향을 끼칠 수 있다.
> 따라서, 미리 데이터베이스에 캐시로 밀어넣어주는 작업을 하기도 하는데, 이를 `캐시 워밍(cache warming`이라고 한다.

### 2. 읽기 전략 - Read Through
![read through](https://velog.velcdn.com/images/wellsy1012/post/94399351-1bf1-4308-a226-2d05c2eaceb9/image.png)
데이터를 읽을 때 무조건 캐시 데이터만 조회.
만약 Cache Misss 발생시 DB에서 해당 데이터를 조회하여 캐시에 저장한다.
- 캐시에 데이터가 없으면, 캐시가 자동으로 DB에서 데이터를 조회하여 캐시에 저장한 후 반환.
**장점**
- 애플리케이션 코드에서 데이터 조회 및 저장 시 캐시와의 상호작용을 신경 쓸 필요가 없다.
-  캐시 관리: 캐시가 데이터베이스와의 데이터 일관성을 자동으로 유지한다.
**단점**
- 캐시 구현 의존: 캐시 라이브러리나 시스템이 read-through 기능을 지원해야 한다.
- 유연성 부족: 특정 데이터에 대한 캐싱 제어가 어려울 수 있다.

### 쓰기 전략과 캐시의 일관성
캐시는 DB에 저장되어있는 데이터를 단순 복사해온 값이다. <mark style="background: #D2B3FFA6;">따라서 원본 데이터와 동일한 값을 갖도록 유지하는것이 필수적이다.</mark>
- [f] **캐시 불일치(cache inconsistency)** :만약 데이터가 변경될 때 원본 데이터베이스에만 업데이트돼 캐시에는 변경된 값이 반영되지 않는다면 데이터간 불일치가 일어난다.

캐시를 이용한 쓰기 전략은 대표적으로 세 가지가 있다.

#### 1. write through
`데이터 베이스에 업데이트 할 때 마다 매번 캐시에도 데이터를 함께 업데이트 시키는 방식`
캐시는 항상 최신 데이터를 가지고 있을 수 있다는 장점이 있지만, 데이터는 매번 2개의 저장소에 저장돼야 하기 때문에 ==데이터를 쓸 때마다 시간이 많이 소요될 수 있다==
- [i] 다시 사용되지 않을 데이터도 무조건 저장되기 때문에, 일종의 리소스 낭비가 된다.
    *따라서, 이 방식을 사용할 경우 TTL 설정이 권장된다.*
    
#### 2. cache invalidation
`데이터 베이스에 값을 업데이트 할 때마다 캐시에서 데이터를 삭제`
- 데이터를 저장하는것보다 삭제하는것이 리소스가 훨씬 적게 사용되기 때문에, write though의 단점이 보완된다.

#### 3. write behind(write back)
쓰기가 빈번하게 발생하는 서비스에 적합
- DB에 대량의 쓰기 작업이 발생하면, 먼저 데이터를 빠르게 접근할 수 있는 캐시에 업데이트 한 뒤, 이후 건수나 시간 간격 등에 따라 *비동기적으로* 데이터베이스에 업데이트 한다.

> 동영상 좋아요 수는 매번 실시간 집계가 필요하지 않다.
> 누군가 업데이트를 할 때 마다 그 데이터가 바로 RDB에 업데이트된다면 심각한 성능 저하를 가져올 수 있다.
> - 좋아요를 누른 데이터를 우선 레디스에 저장해놓은 다음 5분 간격으로 집계해 DB에 저장하는 과정을 거친다면, DB 성능을 향상시켜 애플리케이션의 성능을 향상시킬 수 있다.

- [f] 단, 캐시에 문제가 생길경우, 설정된 기간동안의 데이터가 날라갈 수 있다.

# 캐시에서 데이터 흐름

기본적으로 캐시는 데이터 스토어가 갖고 있는 데이터 중 사용자가 자주 사용할 만한 데이터를 갖고 와서 임시로 저장하는 저장소이다.
- 특히 레디스는 메모리에 모든 데이터를 저장하며, 기본적으로 메모리는 서버의 스토리지보다 훨씬 작은 양을 보관할 수 밖에 없다.
따라서 캐시로 레디스를 사용할 때에는 데이터를 저장함과 동시에 적절한 시간의 TTL 값을 저장하는 것이 좋다.

## 만료 시간
> [!tip] 레디스에서 키가 만료됐다고 해도 바로 메모리에서 삭제되는 것이 아니다.
> `passive` 방식, `active` 방식 두가지 방식으로 삭제된다.
> - `passive` 방식: 클라이언트가 키에 접근하고자 할 때 키가 만료되었다면 메모리에서 수동적으로 삭제
>   사용자가 접근할 때에만 수동적으로 삭제되기 때문에, 이를 passive 방식의 만료라 한다.
>   *그러나 사용자가 다시 접근하지 않는 만료된 키도 있어 이 방식만으로는 충분하지 않다.*
> - `active` 방식: TTL 값이 있는 키 중 20개를 랜덤하게 뽑아낸 뒤, 만료된 키를 모두 메모리에서 삭제한다.
>   만일 25% 이상의 키가 삭제됐다면, 다시 20개의 키를 랜덤하게 뽑은 뒤 확인하고, 아니라면 뽑아놓은 20개의 키 잡합에서 다시 확인한다. 이러한 과정을 1초에 10번씩 수행한다.
>   
>   만료된 키를 곧바로 삭제하지 않기때문에, 키를 삭제하는데 들어가는 리소스를 줄일 수 있지만, 그만큼 메모리를 더 사용할 가능성이 존재한다. 최악의 경우 메모리 1/4 는 이미 만료된 키 값일 수 있다.

## 메모리 관리와 maxmemory-policy 설정
메모리 용량을 초과하는 양의 데이터가 저장되면, 레디스는 내부 정책을 사용해 어떤 키를 삭제할지 결정한다.

**Noevivtion**(default)
데이터가 가득 차더라도, 임의로 데이터를 삭제하지 않고 더 이상 레디스에 데이터를 저장할 수 없다는 에러를 반환하는 설정값이다.
하지만 캐시에 데이터를 저장하지 못해 에러가 발생할 경우 *로직에 따라 장애 상황으로* 이어질 수 있다.
- 이 때, 관리자가 직접 레디스 데이터를 지워야 하기 때문에, 레디스를 캐시로 사용할 때 권장하지 않는다.

**LRU eviction**(Least Recently Used)
레디스에 데이터가 가득 찼을 때, 가장 최근에 사용되지 *않은* 데이터부터 삭제하는 정책.
> 최근에 액세스 되지 않은 데이터는 나중에도 액세스될 가능성이 낮을 것이라는 가정을 전제

레디스는 LRU알고리즘을 이용한 2가지 설정값을 가지고 있다.
- volatile-lru
  만료 시간이 설정돼 있는 키에 한해, LRU 방식으로 키를 삭제
  삭제되면 안되는 값에 대해서는 만료 시간을 지정하지 않는다면, 적합할 수 있다.
  하지만, 이 또한 장애 상황을 유발할 수 있는데, 레디스 내부에 저장된 키에 모두 만료 시간이 지정돼 있지 않다면 이는 neovivtion 상황과 동일하다.
- allkeys-LRU
	모든 키에 대해 LRU 알고리즘을 이용해 데이터를 삭제.

**LFU evivtion** (Least Frequently Used)
가장 <mark style="background: #D2B3FFA6;">자주 사용되지 않는 데이터부터 삭제</mark>
LFU는 LRU와 유사하지만, 키를 액세스하는 패턴에 따라 우선순위가 유동적으로 바뀐다는 점에서 특정 케이스에서는 LRU보다 더 효율적일 수 있다.
키가 오랫동안 사용되지 않았더라도, 과거에 자주 액세스했던 키라면, 나중에도 자주 사용될 수 있다는 가정 하에 우선순위가 높아진다.

LFU또한 2가지 설정값을 갖는다.
- volatile-lfu
	만료 시간이 설정돼있는 키에 한해 LFU 방식으로 키를 삭제
- allkeys-lfu
	모든 키에 대해 LFU아고리즘을 이용 데이터를 삭제

**RANDOM evivtion**
레디스에 저장된 키 중 하나를 임의로 골라내 삭제한다.
삭제될 키 값을 계산하지 않아도 된다는 점에서 레디스의 부하를 줄여줄 수 있는 방법이다.
- 하지만 이 방법은 나중에 데이터를 삭제할 수 도 있기때문에, 오히려불필요함을 유발할 수 있다.
또, LFU, LRU를 찾는데에 큰 리소스를 사용하지 않기때문에, ==굳이 레디스 부하를 위해 random evivtion을 사용할 필요가 없다.==

**volatile-ttl**
만료 시간이 가장 작은 키를 삭제한다. 즉 삭제 예정 시간이 얼마 남지 않은 키를 추출, 해당 키를 먼저 삭제한다.
LRU, LFU와 같이 근사 알고리즘을 이용하기 때문에, 저장되 모든 키를 스캨ㄴ하면서 만료 시간을 비교하지 않아도 되며, 간단하게 키를 찾아낼 수 있다.





