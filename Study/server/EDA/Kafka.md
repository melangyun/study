# Kafka 만들게 된 이유

아파치 카프카는 링크드인에서 처음 개발되어 현재는 아파치 재단에서 관리하고 있는 <u>오픈소스</u>이다.
> 2011년 링크드 인은 수많은 데이터를 실시간으로 처리하는 과정에서 많은 어려움을 겪고 있었다.
> 그 당시 링크드인은 데이터를 전송하고 수신하는 과정에서 다수의 프로듀서와 컨슈머가 필요에 따라 개별적인 연결을 가져가는 구조였고, 그 때문에 하나의 시스템만 추가되어도 통신 구조가 기하급수적으로 복잡해질 수 있었다.(M\*N)구성
> ![다수의 프로듀서와 컨슈머](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZcVr3EmYAFyZfIUJ7Xs3yg.png)

이를 해결하기 위해 중앙화된 메시지와 데이터의 흐름을 관리하는 구조를 가져가기로 했고, 그 과정에서 만들어진 것이 카프카이다.
	
![카프카 중앙제어](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZLC3gKwVudx8BJM01Qdq-Q.png)


스트림(시간이 흐르면서 사용할 수 있게 되는 데이터 요소)으로 데이터를 처리하는 방법에 중점을 둔 시스템을 개발하기 위해서 개발되었다.

Kafka는 실시간으로 데이터 스트림을 수집하여 처리합니다
Kafka 공식 홈페이지 첫 화면에는 Kafka를 '오픈소스 분산 이벤트 스트리밍 플랫폼'으로 표현하고 있다.
> 스트리밍 플랫폼(Streaming Platform)은 데이터 스트림을 읽고 쓰고 저장하고 처리하는 역할을 가진 시스템을 의미한다.

## 원하는 기간동안 데이터를 저장하기 위해 만들어진 스토리지 시스템이다.

신뢰성 있는 데이터의 전달을 보장하고 있다. Kafka를 서로 다른 시스템의 연결 계층으로 사용할 수 있다. Kafka 의 데이터는 복제되고, 영구적이며, 원하는 만큼 보존 가능하다.

## 스트림 프로세싱(Stream Proccessing) 능력이 있다.

> 메시징 시스템은 단순히 메시지 전달에만 초점을 두고있다.

하지만 Kafka는 훨씬 더 적은 코드로 스트림으로부터 파생된 다른 스트림과 데이터 세트를 산출해 낼 수 있는 스트림 프로세싱 능력이 있다.

> [!info] 스트림 프로세싱 능력이란?
> ![스트림 프로세싱](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcuiTuH%2FbtriCvVWKx0%2FcYNH9H48QiLjGy8B1tDQf1%2Fimg.png)
>**연속적으로 들어오는 데이터에 대한 여러 작업을 처리하는 것을 의미**
> - 집계(예: 합계, 평균, 표준 편차와 같은 계산)  
> - 분석(예: 데이터의 패턴을 기반으로 미래 이벤트 예측)  
> - 변환(예: 숫자를 날짜 형식으로 변경)이 포함됩니다. )  
> - 강화(예: 데이터 포인트를 다른 데이터 소스와 결합하여 더 많은 컨텍스트 및 의미 생성)  
> - 수집(예: 데이터를 데이터베이스에 삽입)
>   > **Stream Processing**
> Stream Processing 은 Hadoop으로 했던 Batch Processing 의 상위 개념이다.
> Hadoop의 실시간 버전으로 카프카가 설계되었다.


# Kafka살펴보기

1. 브로커(Broker)
2. 클러스터(Cluster)
3. 토픽과 파티션(Topic, Partition)
4. 메시지(Message)
5. 프로듀서와 컨슈머(Producer, Consumer)
6. 컨슈머 그룹(Consumer Group)
7. 리밸런싱(Rebalancing)
8. 리플리케이션(Replication)



## 1. Broker

하나의 카프카 서버를 `브로커(broker)`라고 한다.
> 동일 노드 내에서 여러개의 broker 서버를 띄울 수도 있다.

>[!info] 이러한 분산 메시지 큐의 정보를 관리해 주는 역할을 하는것이 Zookeeper

`브로커(Broker)`는 `프로듀서(Producer)`로부터 `메시지(Topic)`를 수신하고 `오프셋(offset)` 을 지정한 후 <u>해당 메시지를 디스크에 저장</u>한다.
- [*] kafka의 핵심 기능 중 하나는 보존이다! 일정 기간 메시지를 보존한다.

Kafka의 브로커는 클러스터의 일부로 동작하도록 설계되어 있다. 여러개의 브로커가 하나의 클러스터에 포함될 수 있으며, 그 중 하나는 *클러스터의 컨트롤러(Controller)* 역할을 하게 된다.

> 컨트롤러는 클러스터 내의 각 브로커에게 담당 파티션을 할당하고, 각 브로커들이 정상적으로 작동하는지 모니터링 한다.

## 2. 클러스터

> [!question] 서버 클러스터링
> 여러대의 분산 서버를 네트워크로 연결하여 마치 하나의 거대한 서버처럼 동작하게 만드는 개념
> > 여러대의 서버를 한대로 묶게 되면, 특정 서버에 장애가 발생하더라도 다른 서버에서 외부 요청을 처리할 수 있기 때문에 서비스 전체의 가용성에는 문제가 생기지 않는다.

카프카는 여러대의 서버(Broker)를 묶어서 하나의 거대한 서비스(Cluster)처럼 움직이기 때문에, 특정 서버에 장애가 발생하더라도 카프카를 이용한 클라이언트에게는 정상적인 처리와 응답을 제공할 수 있다.
또, 클러스터 내에 카프카 서버를 추가할 때 마다 그 만큼 메시지 수신과 전달에 대한 처리량이 증가하기 때문에 확장성 측면에서도 장점이 있다.
> 카프카 클러스터 확장은 시스템 전체 사용에 영향을 주지 않으면서 온라인 상태에서 수행이 가능하다.
> 따라서 처음 구축시 소규모 운영, 이후 트래픽의 양에 따라 카프카 서버를 대규모로 손쉽게 늘릴 수 있는 장점을 제공한다.

![카프카 클러스터](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2LIhNJESZV37GYG_dLrbfw.png)

## 3. 토픽과 파티션(Topic, Partition)

![카프카의 토픽과 파티션](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dEeuSOb7Z8K7---q.png)

카프카의 메시지는 토픽(`Topic`) 으로 분류된다.
> 토픽은 DB테이블이나 파일 시스템의 폴더와 유사하다.

하나의 토픽은 여러 개의 파티션(Partition)으로 구성될 수 있다.

- 메시지는 파티션에 추가되는 형태로만 기록되며, 맨 앞부터 제일 끝까지의 순서로 읽힌다.
- 하나의 토픽은 여러개의 파티션을 갖지만,
  **메시지의 처리 순서는 토픽이 아닌 파티션별로 관리**된다.

이 때 각 파티션은 서로 다른 서버에 분산될 수 있다. 이 때문에 하나의 토픽이 여러 서버에 걸쳐 수평적으로 확장될 수 있다. 이는 단일 서버로 처리할 때보다 훨씬 높은 성능을 가질 수 있게 해준다.

>[!warning] 하지만 너무 많은 파티션이 있다면 좋지만은 않다.
>1. 리더-팔로워 동기비용 증가
>2. 컨슈머 그룹의 불균형한 분배
>3. Zookeeper 오버헤드
>	카프카는 Zookeeper를 이용해서 메타데이터와 브로커 간 조정을 관리하는데, 파티션 수가 많아지면 Zookeeper에 대한 부하가 증가 할 수 있다.
>4. 모니터링 및 클러스터 관리의 어려움

## 4. 메시지(Message)

카프카에서 데이터의 기본 단위이다. 
카프카에서는 메시지를 <u>바이트 배열의 데이터</u>로 간주하므로, 특정 형식이나 의미를 갖지 않는다. 
따라서 어떤 데이터 형태이든 저장이 가능하다. 또, 메시지를 읽어들인 후에는 변환하여 사용해야한다.
### 메시지 구조

- 토픽 (Topic)
- 토픽 중 특정 파티션 위치 (Partition)
- 메시지 생성 시간 (Timestamp)
- 메시지 키 (Key)
- 메시지 값 (Value)

### 프로듀서 구조와 메시지 전달 과정

 프로듀서는 다음 4가지 과정을 통해 메시지를 브로커로 전달한다.
 이 과정은 **브로커에 메시지를 전송할 수 있도록 변환하거나, 필요한 값을 지정해주는 과정이다.**
![메시지가 브로커로 전달되는 과정](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FXvurH%2FbtqCJlT9MAh%2FzZK1T4QjFh3aTqibOMXRuk%2Fimg.png)

1. <mark style="background: #D2B3FFA6;">직렬화 (Serializer)</mark>
	요청받은 메시지를 직렬화 한다. 직렬화(Serialization)는 Serializer가 지정된 설정을 통해 처리하며, **메시지의 키와 값은 바이트 뭉치 형태로 변환된다**
2. 파티셔닝 (Partitioner)
	직렬화 과정을 마친 메시지는 Partitioner를 통해 **토픽의 어떤 파티션에 저장될지 결정된다.**
	Partitioner는 정의된 로직에 따라 파티셔닝을 진행하는데, 별도의 Partitioner 설정을 하지 않으면 Round Robbin 형태로 파티셔닝을 한다. (즉, 파티션들에게 골고루 전달할 수 있도록 파티셔닝을 한다.)
	> 단, 이 과정은 메시지 전달 요청에 파티션이 지정되지 않았을 경우에만 진행
3. 메시지 배치 (Record Accumulator)
4. 압축 (Compression)
	만약 메시지 압축이 설정되었다면, 설정된 포맷에 맞춰 메시지를 압축
5. 전달 (Sender)
	 파티셔닝과 압축을 마친 후, 프로듀서는 메시지를 TCP 프로토콜을 통해 브로커 리더 파티션으로 전송
	 하지만 메시지마다 매번 네트워크를 통해 전달하는 것은 비효율적이기에, 프로듀서는 지정된 만큼 메시지를 저장했다가 한 번에 브로커로 전달한다.
> 	이 과정은 프로듀서 내부의 Record Accumulator(RA)가 담당하여 처리한다. RA는 각 토픽 파티션에 대응하는 배치 큐(Batch Queue)를 구성하고 메시지들을 레코드 배치(Record Batch) 형태로 묶어 큐에 저장.


>[!info] kafka는 메시지 직렬화 프레임워크 Avro를 사용한다.
>>메시지는 JSON, XML 형식을 사용할 수 있다. 하지만, 타입에 대한 지원이 부족하고 스키마 버전 간의 호환성이 낮은 문제가 있다.
>
>이를 해결하기 위해 Avro 사용한다. Avro는 데이터를 직렬화하는 형식을 제공한다.
>메시지와 별도로 스키마를 유지 관리하므로 스키마가 변경되어도 애플리케이션 코드를 수정할 필요가 없다.


각 배치 큐에 저장된 레코드 배치들은 때가 되면 각각 브로커에 전달되며 이 과정은 Sender가 처리한다.  Sender는 스레드 형태로 구성되며, **관리자가 설정한 특정 조건에 만족한 레코드 배치를 브로커로 전송한다.** 이때, Sender 스레드는 네트워크 비용을 줄이기 위해 **piggyback 방식**으로 조건을 만족하지 않은 다른 레코드 배치를 조건을 만족한 것과 함께 브로커로 전송한다. 

발행자가 어떤 형태로든 메시지를 구분하여 발행/구독 시스템에 전송한다
> cf) [[EDA(Event Driven Architecture)이란?#^aba780]]

발행/구독 시스템에 전송이 되면 구독자에게 특정 부류의 메시지를 구독할 수 있게 해준다.
이때, 발행되어진 <u>메시지를 저장하고 중계 역할</u>을 `브로커(broker)` 가 수행한다.

## 5. 프로듀서와 컨슈머(Producer, Consumer)

카프카 클라이언트는 프로듀서와 컨슈머가 있다.
프로듀서는 새로운 메시지를 특정 토픽에 생성하는데, 이때 프로듀서는 <mark style="background: #FFF3A3A6;">기본적으로 메시지가 어떤 파티션에 기록하는지는 관여하지 않는다.</mark>

### Comsumer

- 컨슈머는 하나 이상의 토픽을 구독하면서 <u>메시지가 생성된 순서로 읽는다.</u>
- 컨슈머는 메시지를 읽을 때마다 파티션 단위로 오프셋을 유지하여 읽는 메시지의 위치를 알 수 있다.

메시지는 생성된 순서대로 읽으며 메시지의 **오프셋**을 유지하고 있어, 읽고있는 메시지의 위치를 알 수 있다.
> 컨슈머가 메시지 읽기를 중단하여도, 이어서 읽을 수 있다.	


### offset

![Consumer offset의 개념](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ebQh-QXPfPugm7ZSmNxhOw.png)

- commit offset: 컨슈머로부터 '여기까지 오프셋은 처리했다'
- current offset: 컨슈머가 어디까지 데이터를 읽었는가를 나타냄

컨슈머는 메시지를 읽을 때 마다 **파티션단위**로 오프셋을 유지하여 읽는 메시지의 위치를 알 수 있다

## 6. 컨슈머 그룹(Consumer Group)

카프카 컨슈머들은 컨슈머 그룹에 속하게 된다.
여러개의 컨슈머가 같은 컨슈머 그룹에 속할 때에는 각 컨슈머가 해당 토픽의 다른 파티션을 분담헤서 메시지를 읽을 수 있다.
> 하나의 컨슈머 그룹에 더 많은 컨슈머를 추가하면 카프카 토픽의 데이터 소비를 확장할 수 있다.
> 즉, 더 많은 컨슈머를 추가하는 것이 메시지 소비 성능 확장에 중요한 방법이 된다.

- [i] 위에서 설명한 `offset`의 위치를 알고 있기 때문에 문제가 생기지 않는다.

> [!warning] 한 토픽의 각 파티션은 <u>하나의 컨슈머만 처리할 수 있다.</u>
>  '각 컨슈머'가 '각 파티션'에 대응되는 것을 파티션 소유권(*Partition Ownership*) 이라고 한다.
>   그렇기 때문에 **반드시 해당 topic의 파티션은 그 consumer group과 1:n 매칭을 해야한다.**
>   - [f] 그렇기 때문에 하나의 토픽 내 파티션 개수보다 더 많은 컨슈머를 추가하는 것은 의미가 없다.

> [!tip] 같은 그룹 내의 컨슈머가 다운된다면, 파티션 재조정(리밸런스)를 통해 다른 컨슈머가 파티션 소비를 이어서 하게 된다.

![4개 파티션 - 2개 컨슈머](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-D_BnAqf3CjYUBpet-vX7w.png)

![4개 파티션에 4개 컨슈머](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w0qI9R9moq-8XjqFJA8P2w.png) 
> 해당 경우 최대의 읽기 성능을 갖는다.

![일하지 않는 컨슈머가 발생](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2nHE_llHWyJhuYvv7FMbPA.png)

4개의 파티션에 5개의 컨슈머. 일하지 않는 컨슈머가 발생한다.

### 카프카는 하나의 토픽에 여러 개의 컨슈머 그룹이 붙어서 메시지를 읽을 수 있는 다중 컨슈머 기능을 제공

![다중 컨슈머](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g-RMS23wSIuN9P05xGZbLQ.png)

여러 개의 컨슈머 그룹이 서로간의 상호 간섭 없이 각자의 오프셋으로 각자의 순서에 맞게 메시지를 읽고 처리할 수 있다.
같은 토픽의 메시지를 읽어야 하는 여러 개의 애플리케이션이 있다면 각각의 애플리케이션마다 각자의 컨슈머 그룹을 갖도록 하면 된다.
> 이때문에 보통 컨슈머 그룹명은 *애플리케이션 이름*과 일치시켜 관리하는 편.
> 컨슈머 그룹 = 애플리케이션 단위

## 7. 리밸런싱 (Rebalancing)

- [i] 한 컨슈머로부터 다른 컨슈머로 소유권이 이전되는것.

리밸런싱은 보통 다음과 같은 상황에서 발생한다.

1. 컨슈머 그룹 내에 새로운 컨슈머 추가
2. 특정 컨슈머에 문제가 생겨 중단
3. 해당 컨슈머 그룹이 바라보는 토픽 내에 새로운 파티션이 생김

리밸런싱은 컨슈머 그룹의 가용성과 확장성을 높여주기 때문에 중요하지만, *리밸런싱 동안 컨슈머는 메시지를 읽을수 없는 상태에 빠진다(stop the world).*
따라서 안전하게 리밸런싱 하고, 부적절한 리밸런싱을 피하는것이 중요하다.

## 8. 리플리케이션(Replication)

리플리케이션은 카프카 클러스터의 가용성을 보장하는 개념이다.
카프카 메시지는 토픽에 저장되며, 각 토픽은 여러 파티션으로 구성된다. 이 때 각각의 파티션은 다수의 리플리카(Replica, 복제본)을 가질 수 있다. 리플리카는 두 가지 형태가 있다.

![kafka Cluster Controller](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FctpGrZ%2FbtriAGdtOaR%2FHy6BPK2nfC6B43nEuXfYN1%2Fimg.png)

1. 리더 리플리카 (Leader Replica)
	각 **파티션**은 리더로 지정된 하나의 리플리카를 가진다
	일관성을 보장하기 위해 모든 <u>프로듀서와 컨슈머 클라이언트의 요청은 리더를 통해 처리</u>된다.
	(읽기와 쓰기 요청 모두 리더 리플리카를 통해 처리된다.)
2. 팔로워 리플리카(Follower Replica)
	각 파티션 리더를 제외한 나머지 리플리카는 모두 팔로워라고 한다.
	팔로워는 클라이언트 요청을 서비스하지 않고, 단순히 리더의 메시지를 복제하여 리더의 것과 동일하게 유지하는 역할만 한다.

- [i] 이후 특정 파티션의 리더 리플리카가 중단되는 경우에는 팔로워 리플리카 중 하나가 해당 파티션의 리더로 선출된다.

리더 리플리카와 동기화 하기위해 팔로워 리플리카들은 리더에게 Fetch 요청을 전송한다.
- 이 것은 컨슈머가 메시지를 읽기 위해 전송하는 것과 같은 타입이다.
이 때, 최신 메시지를 계속 요청하는 팔로워를 `In-SyncReplica(ISR)`이라고 하고, 그렇지 않은 리플리카(모종의 이유로 패치가 이루어지지 않았다면)를 `Out-Sync-Replica(OSR)`라고 한다.
(당연히 동기화 되지 않은 리플리카는 추후 리더가 장애가 생겼을 때 새로운 리더가 될 수 없다.)

> [!question] OSR의 기준?
> 모든 replica가 ISR로 유지되기 위해 주기적으로 fetch를 수행한다. 이 과정에서 차질이 생기면 ISR에서 벗어나 OSR이 된다.
> 
> >OSR이 다시 동기화 되면 ISR이 된다. 동기화가 빈번하게 실패하거나, OSR의 수가 급증하는 경우, 데이터 복제의 신뢰성이 감소할 수 있으므로 예방적으로 이를 관리해야 한다.



# 메시지 발행/ 구독


# 클러스터 컨트롤러(Kluster Controller)

클러스터 컨트롤러는 같은 클러스터의 각 브로커에게 담당 파티션을 할당한다.
클러스터 컨트롤러는 브로커들이 정상적으로 동작하는지 모니터링 관리 기능을 맡고 있다.



각 파티션은 클러스터의 한 브로커가 소유하며, 그 브로커를 파티션 리더l(leader)라고 한다.
같은 파티션이 여러 브로커에 지정될 수 있으며 이때는 해당 파티션이 복제된다.

파티션의 메시지는 중복으로 저장되지만
한 브로커에 장애가 생기면 다른 브로커가 소유권을 인계받아 그 파티션을 처리할 수 있다.

> [!tip] 각 파티션을 사용하는 모든 컨슈머, 프로듀서는 파티션 리더에 연결해야 한다.

# 다중 클러스터

**다중 클러스터의 장점**
1. 데이터 타입에 따라 구분하여 처리할 수 있다
2. 보안 요구사항을 분리해서 처리할 수 있다
3. 재해 복구를 대비한 다중 데이터센터를 유지할 수 있다

# 다중 데이터센터 아키텍처

![다중 데이터센터 아키텍처](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Frf7SJ%2FbtriGjHC0xl%2Fk3jurlzXCsE8EGrJFhkx31%2Fimg.png)

데이터센터 B의 카프카 클러스터를 -> 미러메이커 A를 이용해 -> 카프카 집중 클러스터 A에 생산할 수 있다.

데이터센터 B의 카프카 집중 클러스터 B를 -> 미러메이커 C를 이용해 -> 카프카 집중 클러스터 C에 생산할 수 있다.

# 카프카를 선택하는 이유

1. 다중 프로듀서
   여러 Producer가 많은 Topic을 사용해도, 같은 Topic을 함께 사용해도 무리 없이 많은 Producer 메시지를 처리할 수 있다. 여러 프런트엔드 시스템으로부터 데이터를 수집하고 일관성을 유지하는데 이상적이다.
2. 다중 컨슈머
   Kafka는 많은 Consumer가 상호 간섭없이 어떤 메시지 스트림을 읽을 수 있게 지원한다.<u>한 클라이언트가 특정 메시지를 소비하면 다른 클라이언트에서 그 메시지를 사용할 수 없는 큐(queue) 시스템과 다르다.</u>
   Kafka Consumer는 Consumer Group의 멤버가 되어 메시지 스트림을 공유할 수 있다(Consumer Group 이미지 참고)
3. 확장성
   Kafka는 어떤 크기의 데이터도 쉽게 처리할 수 있음 (크던, 작던)
   확장 작업은 시스템 전체 사용에 영향을 주지 않고 클러스터가 온라인 상태일 때도 수행될 수 있다. 여러 개의 브로커로 구성된 클러스터는 개별적인 브로커의 장애를 처리하면서 클라이언트에게 지속적인 서비스를 할 수 있다. 동시에 여러 브로커에 장애가 생겨도 정상적으로 처리할 수 있습니다. ‘복제 팩터’를 더 큰 값으로 지정하여 구성할 수 있다.
4. 영속성
   메시지(Topic)를 디스크에 저장함으로써 영속성을 보장한다.
   장애 발생시에도 Producer의 개입 없이 offset rewind를 통해 데이터를 다시 보내주는 것이 가능하다.
   > (데이터 정합성을 지키기 어려운 MSA 환경에서 매우 중요한 요소입니다.)

(디스크에 저장함에도 불구하고 디스크 순차 I/O 읽기와 Zero Copy 기법으로 메모리와 같이 빠른 성능을 보여주고 있다.)

---
[Kafka 이벤트 스트리밍 이해하기](https://wjjeong.tistory.com/56)
[Kafka 이해하기](https://medium.com/@umanking/%EC%B9%B4%ED%94%84%EC%B9%B4%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0-%ED%95%98%EA%B8%B0%EC%A0%84%EC%97%90-%EB%A8%BC%EC%A0%80-data%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0%ED%95%B4%EB%B3%B4%EC%9E%90-d2e3ca2f3c2)
[카프카 프로듀서 (Kafka Producer)](https://always-kimkim.tistory.com/entry/kafka101-producer)

아래 글 시리즈 괜찮은듯!
[Apache Kafka 간략하게 살펴보기](https://medium.com/@greg.shiny82/apache-kafka-%EA%B0%84%EB%9E%B5%ED%95%98%EA%B2%8C-%EC%82%B4%ED%8E%B4%EB%B3%B4%EA%B8%B0-343ad84a959b)
