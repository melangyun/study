메시지플랫폼은 한달에 약 2개의 장애가 발생함
- 통신사/ FCM (44)
- 내부버그 (30)
- 벤더사 장애 (17)
	- 벤더사 삼중화가 되어있음
	- 이중화 + 비용 효율화
- 카프카 장애 (10)
	- 카프카 자체 클러스터도 이중화
# 장애를 이겨내기 위한 노력으로

- 발송이 끝나면 발송 히스토리를 모니터링 -> 특정 통신사에 장애가 발생했다는 것을 빠르게 인지해야함. 트래픽 전환 > 수동으로 전환할수도 있음

# 아키텍처 개선
메시지 플랫폼은 가용성을 중심으로 운영함

`Kafka exactly Once` 때문에 장애가 발생했었는데
- 멱등성 프로듀서
- 트랜잭션
트랜잭셔

api한번의 호출로 최대 100명에게 발송을 해야할것같은데 > 중복이면 안됨

**Kafka Exactly Once**
적정 수준의 중복 방지
- 인프라 비용 감소
- 아키텍처의 심플함

-> 플랫폼 유지 비용 증가로 이어짐

Kafka exactly once 제거를 결정 -> 중복을 위해서 어떤 아키텍처를 짤것인가

redis 에 hash를 올려서 사용
- hash 는 무엇으로 생성하지?
- 카프카 내부에서 발생하는 중복만 제거
- 용량이 많아서 롤백..

# 3배 트래픽을 위한 여정
- 가장 쉬운 방법: 파티션 * 3 > 파티션 늘리는데 제약이 있었음
	- 장애 복구 타임 증가
	- 터밋 latency 증가
	- 리소스 사용량 증가
	- 늘어난 파티션은 줄일 수 없음 등
	- 효과는 불확실하나 비용과 리스크는 커지는데 비가역적임
- 
